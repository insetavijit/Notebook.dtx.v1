{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1973993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enterprise-level Technical Analysis Framework\n",
    "Provides fluent interface for financial data analysis with comprehensive error handling\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "from typing import Union, Optional, Dict, List, Callable, Any\n",
    "from abc import ABC, abstractmethod\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693071d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparisonType(Enum):\n",
    "    \"\"\"Enumeration of supported comparison operations\"\"\"\n",
    "    ABOVE = \"above\"\n",
    "    BELOW = \"below\"\n",
    "    CROSSED_UP = \"crossed_up\"\n",
    "    CROSSED_DOWN = \"crossed_dn\"\n",
    "    EQUALS = \"equals\"\n",
    "    GREATER_EQUAL = \"greater_equal\"\n",
    "    LESS_EQUAL = \"less_equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnalysisResult:\n",
    "    \"\"\"Data class to encapsulate analysis results\"\"\"\n",
    "    column_name: str\n",
    "    operation: str\n",
    "    success: bool\n",
    "    message: str = \"\"\n",
    "    data: Optional[pd.Series] = None\n",
    "\n",
    "class TAException(Exception):\n",
    "    \"\"\"Custom exception for Technical Analysis operations\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnValidator:\n",
    "    \"\"\"Validates column existence and data types\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_column_exists(df: pd.DataFrame, column: str) -> bool:\n",
    "        \"\"\"Check if column exists in DataFrame\"\"\"\n",
    "        if column not in df.columns:\n",
    "            raise TAException(f\"Column '{column}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_numeric_column(df: pd.DataFrame, column: str) -> bool:\n",
    "        \"\"\"Validate that column contains numeric data\"\"\"\n",
    "        ColumnValidator.validate_column_exists(df, column)\n",
    "        if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            raise TAException(f\"Column '{column}' must contain numeric data, got {df[column].dtype}\")\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_numeric_value(value: Union[str, int, float]) -> float:\n",
    "        \"\"\"Convert and validate numeric value\"\"\"\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            raise TAException(f\"Value '{value}' cannot be converted to numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ec1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseComparator(ABC):\n",
    "    \"\"\"Abstract base class for comparison operations\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def compare(self, df: pd.DataFrame, x: str, y: Union[str, float],\n",
    "                new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Perform the comparison operation\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _generate_column_name(self, x: str, y: Union[str, float], operation: str) -> str:\n",
    "        \"\"\"Generate descriptive column name\"\"\"\n",
    "        y_str = str(y).replace('.', '_')\n",
    "        return f\"{x}_{operation}_{y_str}\"\n",
    "\n",
    "    def _add_constant_column(self, df: pd.DataFrame, name: str, value: float) -> pd.DataFrame:\n",
    "        \"\"\"Add a constant value column if it doesn't exist\"\"\"\n",
    "        if name not in df.columns:\n",
    "            df[name] = value\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5145b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AboveComparator(BaseComparator):\n",
    "    \"\"\"Compare if column X is above Y\"\"\"\n",
    "\n",
    "    def compare(self, df: pd.DataFrame, x: str, y: Union[str, float],\n",
    "                new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        ColumnValidator.validate_numeric_column(df, x)\n",
    "\n",
    "        if isinstance(y, (int, float)):\n",
    "            df = self._add_constant_column(df, str(y), float(y))\n",
    "            y_col = str(y)\n",
    "        else:\n",
    "            ColumnValidator.validate_numeric_column(df, y)\n",
    "            y_col = y\n",
    "\n",
    "        new_col = new_col or self._generate_column_name(x, y, \"above\")\n",
    "        df[new_col] = (df[x] > df[y_col]).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BelowComparator(BaseComparator):\n",
    "    \"\"\"Compare if column X is below Y\"\"\"\n",
    "\n",
    "    def compare(self, df: pd.DataFrame, x: str, y: Union[str, float],\n",
    "                new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        ColumnValidator.validate_numeric_column(df, x)\n",
    "\n",
    "        if isinstance(y, (int, float)):\n",
    "            df = self._add_constant_column(df, str(y), float(y))\n",
    "            y_col = str(y)\n",
    "        else:\n",
    "            ColumnValidator.validate_numeric_column(df, y)\n",
    "            y_col = y\n",
    "\n",
    "        new_col = new_col or self._generate_column_name(x, y, \"below\")\n",
    "        df[new_col] = (df[x] < df[y_col]).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossedUpComparator(BaseComparator):\n",
    "    \"\"\"Detect when X crosses above Y\"\"\"\n",
    "\n",
    "    def compare(self, df: pd.DataFrame, x: str, y: Union[str, float],\n",
    "                new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        ColumnValidator.validate_numeric_column(df, x)\n",
    "\n",
    "        if isinstance(y, (int, float)):\n",
    "            df = self._add_constant_column(df, str(y), float(y))\n",
    "            y_col = str(y)\n",
    "        else:\n",
    "            ColumnValidator.validate_numeric_column(df, y)\n",
    "            y_col = y\n",
    "\n",
    "        new_col = new_col or self._generate_column_name(x, y, \"crossed_up\")\n",
    "        diff = df[x] - df[y_col]\n",
    "        df[new_col] = ((diff > 0) & (diff.shift(1) <= 0)).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641573f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossedDownComparator(BaseComparator):\n",
    "    \"\"\"Detect when X crosses below Y\"\"\"\n",
    "\n",
    "    def compare(self, df: pd.DataFrame, x: str, y: Union[str, float],\n",
    "                new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        ColumnValidator.validate_numeric_column(df, x)\n",
    "\n",
    "        if isinstance(y, (int, float)):\n",
    "            df = self._add_constant_column(df, str(y), float(y))\n",
    "            y_col = str(y)\n",
    "        else:\n",
    "            ColumnValidator.validate_numeric_column(df, y)\n",
    "            y_col = y\n",
    "\n",
    "        new_col = new_col or self._generate_column_name(x, y, \"crossed_down\")\n",
    "        diff = df[x] - df[y_col]\n",
    "        df[new_col] = ((diff < 0) & (diff.shift(1) >= 0)).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a668631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparatorFactory:\n",
    "    \"\"\"Factory class to create appropriate comparator instances\"\"\"\n",
    "\n",
    "    _comparators: Dict[str, BaseComparator] = {\n",
    "        ComparisonType.ABOVE.value: AboveComparator(),\n",
    "        ComparisonType.BELOW.value: BelowComparator(),\n",
    "        ComparisonType.CROSSED_UP.value: CrossedUpComparator(),\n",
    "        ComparisonType.CROSSED_DOWN.value: CrossedDownComparator(),\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_comparator(cls, operation: str) -> BaseComparator:\n",
    "        \"\"\"Get comparator instance for the given operation\"\"\"\n",
    "        comparator = cls._comparators.get(operation.lower())\n",
    "        if not comparator:\n",
    "            available = list(cls._comparators.keys())\n",
    "            raise TAException(f\"Unsupported operation '{operation}'. Available: {available}\")\n",
    "        return comparator\n",
    "\n",
    "    @classmethod\n",
    "    def register_comparator(cls, operation: str, comparator: BaseComparator):\n",
    "        \"\"\"Register a new comparator for custom operations\"\"\"\n",
    "        cls._comparators[operation.lower()] = comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryParser:\n",
    "    \"\"\"Parse natural language queries into structured operations\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_query(query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Parse multi-line query string into structured operations\"\"\"\n",
    "        operations = []\n",
    "\n",
    "        for line in query.strip().splitlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Parse pattern: \"Column1 operation Column2/Value\"\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 3:\n",
    "                col1 = parts[0]\n",
    "                operation = parts[1].lower()\n",
    "                col2 = parts[-1]  # Last part is the target\n",
    "\n",
    "                operations.append({\n",
    "                    'column1': col1,\n",
    "                    'operation': operation,\n",
    "                    'column2': col2\n",
    "                })\n",
    "            else:\n",
    "                logger.warning(f\"Skipping malformed query line: {line}\")\n",
    "\n",
    "        return operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1795c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechnicalAnalyzer:\n",
    "    \"\"\"Main class providing fluent interface for technical analysis\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"Initialize with DataFrame\"\"\"\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TAException(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "        self._df = df.copy()  # Work with copy to avoid modifying original\n",
    "        self._operations_log: List[AnalysisResult] = []\n",
    "        logger.info(f\"Initialized TechnicalAnalyzer with DataFrame shape: {self._df.shape}\")\n",
    "\n",
    "    @property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        \"\"\"Get the current DataFrame\"\"\"\n",
    "        return self._df\n",
    "\n",
    "    @property\n",
    "    def operations_log(self) -> List[AnalysisResult]:\n",
    "        \"\"\"Get log of all operations performed\"\"\"\n",
    "        return self._operations_log\n",
    "\n",
    "    def above(self, x: str, y: Union[str, float], new_col: Optional[str] = None) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Fluent interface for above comparison\"\"\"\n",
    "        return self._execute_operation(ComparisonType.ABOVE.value, x, y, new_col)\n",
    "\n",
    "    def below(self, x: str, y: Union[str, float], new_col: Optional[str] = None) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Fluent interface for below comparison\"\"\"\n",
    "        return self._execute_operation(ComparisonType.BELOW.value, x, y, new_col)\n",
    "\n",
    "    def crossed_up(self, x: str, y: Union[str, float], new_col: Optional[str] = None) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Fluent interface for crossed up detection\"\"\"\n",
    "        return self._execute_operation(ComparisonType.CROSSED_UP.value, x, y, new_col)\n",
    "\n",
    "    def crossed_down(self, x: str, y: Union[str, float], new_col: Optional[str] = None) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Fluent interface for crossed down detection\"\"\"\n",
    "        return self._execute_operation(ComparisonType.CROSSED_DOWN.value, x, y, new_col)\n",
    "\n",
    "    def _execute_operation(self, operation: str, x: str, y: Union[str, float],\n",
    "                          new_col: Optional[str] = None) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Execute a comparison operation and log the result\"\"\"\n",
    "        try:\n",
    "            comparator = ComparatorFactory.get_comparator(operation)\n",
    "            self._df = comparator.compare(self._df, x, y, new_col)\n",
    "\n",
    "            # Log successful operation\n",
    "            result_col = new_col or comparator._generate_column_name(x, y, operation)\n",
    "            result = AnalysisResult(\n",
    "                column_name=result_col,\n",
    "                operation=f\"{x} {operation} {y}\",\n",
    "                success=True,\n",
    "                message=\"Operation completed successfully\",\n",
    "                data=self._df[result_col]\n",
    "            )\n",
    "            self._operations_log.append(result)\n",
    "            logger.info(f\"✓ {result.operation} -> {result.column_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log failed operation\n",
    "            result = AnalysisResult(\n",
    "                column_name=\"\",\n",
    "                operation=f\"{x} {operation} {y}\",\n",
    "                success=False,\n",
    "                message=str(e)\n",
    "            )\n",
    "            self._operations_log.append(result)\n",
    "            logger.error(f\"✗ {result.operation}: {result.message}\")\n",
    "            raise TAException(f\"Operation failed: {e}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def execute_query(self, query: str) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Execute a natural language query\"\"\"\n",
    "        operations = QueryParser.parse_query(query)\n",
    "\n",
    "        for op in operations:\n",
    "            try:\n",
    "                # Convert numeric strings to float\n",
    "                try:\n",
    "                    col2 = float(op['column2'])\n",
    "                except ValueError:\n",
    "                    col2 = op['column2']\n",
    "\n",
    "                self._execute_operation(op['operation'], op['column1'], col2)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to execute query operation {op}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_signals(self, column: str) -> pd.Series:\n",
    "        \"\"\"Get signal series for a specific column\"\"\"\n",
    "        if column not in self._df.columns:\n",
    "            raise TAException(f\"Column '{column}' not found\")\n",
    "        return self._df[column]\n",
    "\n",
    "    def get_active_signals(self, column: str) -> pd.DataFrame:\n",
    "        \"\"\"Get only rows where signal is active (value = 1)\"\"\"\n",
    "        if column not in self._df.columns:\n",
    "            raise TAException(f\"Column '{column}' not found\")\n",
    "        return self._df[self._df[column] == 1]\n",
    "\n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of all operations performed\"\"\"\n",
    "        summary_data = []\n",
    "        for result in self._operations_log:\n",
    "            summary_data.append({\n",
    "                'Operation': result.operation,\n",
    "                'Column': result.column_name,\n",
    "                'Success': result.success,\n",
    "                'Message': result.message,\n",
    "                'Active_Signals': result.data.sum() if result.data is not None else 0\n",
    "            })\n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "    def reset(self) -> 'TechnicalAnalyzer':\n",
    "        \"\"\"Reset to original DataFrame state\"\"\"\n",
    "        # Keep only original columns (remove generated ones)\n",
    "        original_cols = [col for col in self._df.columns\n",
    "                        if not any(op in col.lower() for op in ['above', 'below', 'cross'])]\n",
    "        self._df = self._df[original_cols]\n",
    "        self._operations_log.clear()\n",
    "        logger.info(\"Reset analyzer to original state\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3df0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabr(df: pd.DataFrame) -> TechnicalAnalyzer:\n",
    "    \"\"\"Factory function to create TechnicalAnalyzer instance\"\"\"\n",
    "    return TechnicalAnalyzer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage and demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data creation for demonstration\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "    sample_data = {\n",
    "        'DateTime': dates,\n",
    "        'Close': 100 + np.cumsum(np.random.randn(100) * 0.5),\n",
    "        'EMA_21': 100 + np.cumsum(np.random.randn(100) * 0.3),\n",
    "        'RSI_14': 30 + 40 * np.random.rand(100),\n",
    "        'Volume': 1000 + 500 * np.random.rand(100)\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n",
    "\n",
    "    # Demonstration of fluent interface\n",
    "    print(\"=== Enterprise Technical Analysis Framework Demo ===\\n\")\n",
    "\n",
    "    # Create analyzer instance\n",
    "    analyzer = cabr(df)\n",
    "\n",
    "    # Chain operations using fluent interface\n",
    "    result = (analyzer\n",
    "              .above('Close', 'EMA_21')\n",
    "              .below('RSI_14', 70)\n",
    "              .crossed_up('Close', 'EMA_21')\n",
    "              .above('Volume', 1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e329309",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Close above EMA_21\n",
    "RSI_14 below 30\n",
    "Volume above 1500\n",
    "\"\"\"\n",
    "\n",
    "analyzer.execute_query(query)\n",
    "\n",
    "# Display results\n",
    "print(\"Operations Summary:\")\n",
    "print(analyzer.summary())\n",
    "print(f\"\\nDataFrame shape: {analyzer.df.shape}\")\n",
    "print(f\"\\nGenerated columns: {[col for col in analyzer.df.columns if col not in df.columns]}\")\n",
    "\n",
    "# Get specific signals\n",
    "if 'Close_above_EMA_21' in analyzer.df.columns:\n",
    "    active_signals = analyzer.get_active_signals('Close_above_EMA_21')\n",
    "    print(f\"\\nActive 'Close above EMA_21' signals: {len(active_signals)} out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('auto-indig.csv')\n",
    "\n",
    "# Fluent interface - your requested syntax\n",
    "analyzer = (cabr(df)\n",
    "    .above('Close', 'EMA_21')\n",
    "    .below('RSI_14', 70)\n",
    "    .crossed_up('Close', 'EMA_21'))\n",
    "\n",
    "# Natural language queries\n",
    "query = \"\"\"print(analyzer.df.head())\n",
    "Close above EMA_21\n",
    "RSI_14 below 30\n",
    "Volume crossed_up 1000\n",
    "\"\"\"\n",
    "analyzer.execute_query(query)\n",
    "\n",
    "# Get results\n",
    "print(analyzer.summary())\n",
    "active_signals = analyzer.get_active_signals('Close_above_EMA_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.df.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTXV1.0",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
